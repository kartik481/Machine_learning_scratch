# Machine learning from scratch
Creating methods from scratch with minimal use of inbuilt functions...

(Check the notebook ML_methods.ipynb)

## Conclusions:
1. With a appropriate step size gradient descent can converge faster or might not converge but it's the bottleneck of the algorithm
2. To select appropriate step size, we can use the bayesian optimization.

