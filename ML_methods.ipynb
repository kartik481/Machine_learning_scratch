{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124e9f66-7a03-4279-a86c-3ade7859ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the required libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "iris = datasets.load_iris() ## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec04118-c8c0-4e0b-aac2-5f1bdfd0b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.concatenate((iris.data, iris.target[:,None]), axis=1)\n",
    "\n",
    "# Shuffling the data \n",
    "np.random.shuffle(Data)\n",
    "\n",
    "## Slicing the Dataset as required for labels \n",
    "X = Data[:,:4]\n",
    "yy = Data[:,4]\n",
    " \n",
    "## Scaling the data to make gradient descent work smoothly\n",
    "\n",
    "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec43a6e-6e13-46f7-9446-afdf314d58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data is already cleaned so no need of preprocessing\n",
    "X_train = X[:100,:]\n",
    "X_val = X[100:130,:]\n",
    "X_test = X[130:150,:]\n",
    "\n",
    "yy_train = yy[:100]\n",
    "yy_val = yy[100:130]\n",
    "yy_test = yy[130:150]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de351873-2301-4f83-8058-3bd65f48554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear regression Using the least square method \n",
    "\n",
    "def lin_reg(X, yy, alpha):\n",
    "    k = len(X[1])\n",
    "    yy = np.concatenate((yy, np.zeros(k))) \n",
    "    z_k = np.sqrt(alpha) * np.eye(k)\n",
    "    X = np.vstack((X,z_k))  \n",
    "    \n",
    "    b = np.concatenate((np.ones(len(X)-k), np.zeros(k)))[:,None]\n",
    "\n",
    "    X = np.insert(X,[0],b,axis=1)\n",
    "\n",
    "    w_fit=np.linalg.lstsq(X, yy, rcond=None)[0]\n",
    "    \n",
    "    \n",
    "    return w_fit[1:], w_fit[0] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c8a8d6-e16d-4ed1-ae38-be91a202bcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias is: -0.02385942299664876\n",
      "Weights are: \n",
      " [ 0.22334537 -0.26152559  0.92774672  1.30104487]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = 1 ## value for lambda parameter\n",
    "\n",
    "## Extracting the required parameters\n",
    "ww0, bb0 = lin_reg(X_train, yy_train, alpha)\n",
    "\n",
    "print(\"Bias is:\",bb0)\n",
    "print(\"Weights are:\",\"\\n\",ww0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d96c880-b7e2-4f95-946c-f9245b06dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cost functions\n",
    "\n",
    "## Mean Square error cost function\n",
    "def mse(pred,yy):\n",
    "    return np.mean((pred-yy)**2)\n",
    "\n",
    "## mLogloss for multi-classification\n",
    "def mlogloss(pred, yy):\n",
    "    yy = np.int_(yy)\n",
    "    return -np.mean(np.log(pred[np.arange(len(yy)), yy]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d099baaa-4c1c-4504-b031-b102d4bbcef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means square for training set(using least square method): 0.05145419928189548\n",
      "Means square for validation set(using least square method): 0.06793670471653827\n"
     ]
    }
   ],
   "source": [
    "## for least square method\n",
    "pred1_train = np.dot(X_train,ww0)+bb0\n",
    "pred2_val = np.dot(X_val,ww0)+bb0\n",
    "print(\"Means square for training set(using least square method):\",mse(pred1_train, yy_train))\n",
    "print(\"Means square for validation set(using least square method):\",mse(pred2_val, yy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1417ed8c-9db6-4d8b-98af-2b3fbaab9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the softmax function\n",
    "def softmax(x):\n",
    "    \n",
    "    # subtracting the max of z for numerical stability.\n",
    "    res = np.exp(x - np.max(x))\n",
    "    \n",
    "    # Calculating softmax for all examples.\n",
    "    for i in range(len(x)):\n",
    "        res[i] /= np.sum(res[i])\n",
    "        \n",
    "    return res\n",
    "\n",
    "## Defining one-hot encoder\n",
    "def one_hot(yy, c):\n",
    "    yy = np.int_(yy)\n",
    "    yy_hot = np.zeros((len(yy), c))\n",
    "    yy_hot[np.arange(len(yy)), yy] = 1\n",
    "\n",
    "    return yy_hot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Simple gradient descent method for linear regression\n",
    "\n",
    "def grad_des(X_train, yy_train, learning_rate, epochs):\n",
    "    n=len(X_train)\n",
    "    ww = np.random.randn(len(X[1]))\n",
    "    bb = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        yy_pred = np.dot(X_train, ww)+bb\n",
    "        \n",
    "        \n",
    "        cost = mse(yy_pred, yy_train)\n",
    "        if i%100==0:\n",
    "            print(\"MSE(train) for {0}th epoch is {1}\".format(i, cost))\n",
    "        D_ww = -2/n * np.sum(np.transpose(X_train) * (yy_train-yy_pred)) \n",
    "        D_bb = -2/n * np.sum((yy_train-yy_pred))\n",
    "        \n",
    "        ## Updating the parameters\n",
    "        ww -=learning_rate*D_ww\n",
    "        bb -=learning_rate*D_bb\n",
    "        \n",
    "        ## plotting the cost w.r.t to each iteration\n",
    "        plt.scatter(i, cost)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Cost\")\n",
    "        \n",
    "## Gradient descent for softmax algorithm\n",
    "def grad_des_multi(X_train, yy_train, C, learning_rate, epochs):\n",
    "    N, M = X_train.shape\n",
    "    ww = np.random.randn(M,C)\n",
    "    bb = np.zeros(C)\n",
    "    cost =[]\n",
    "    for i in range(epochs):\n",
    "        yy_pred = softmax(np.dot(X_train, ww)+bb)\n",
    "        \n",
    "        yy_hot = one_hot(yy_train, C)\n",
    "        \n",
    "        ## Gradient of mlog-loss w.r.t ww and bb\n",
    "        D_ww = (1/N) * np.dot(np.transpose(X_train),(yy_pred - yy_hot))\n",
    "        D_bb = (1/N) * np.sum(yy_pred - yy_hot)\n",
    "        \n",
    "        ## Updating the parameters\n",
    "        \n",
    "        ww = ww - learning_rate * D_ww\n",
    "        bb = bb - learning_rate * D_bb\n",
    "        \n",
    "\n",
    "        loss = mlogloss(yy_pred, yy_train)\n",
    "        cost.append(loss)\n",
    "        if i%1000==0:\n",
    "            print(\"loss for {0}th epoch => {1}\".format(i, loss))\n",
    "        plt.scatter(i, loss)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Cost\")\n",
    "    return cost, ww, bb\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83daff05-fb08-47d6-9b15-96a042f5d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 0th epoch => 1.0947858881917854\n",
      "loss for 1000th epoch => 0.4043436166514182\n",
      "loss for 2000th epoch => 0.3820509427936063\n",
      "loss for 3000th epoch => 0.3732698052100391\n",
      "loss for 4000th epoch => 0.3690540993889846\n",
      "loss for 5000th epoch => 0.36678030850908405\n",
      "loss for 6000th epoch => 0.36544011248634445\n",
      "loss for 7000th epoch => 0.36458725790387075\n",
      "loss for 8000th epoch => 0.3640052522696965\n",
      "loss for 9000th epoch => 0.36358191024387876\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Total no of iteration to do\n",
    "epochs = 10000\n",
    "\n",
    "#grad_des(X_train, yy_train, 0.1, epochs)\n",
    "\n",
    "C = 3   ## No. of classes\n",
    "\n",
    "## Extracting the required parameters \n",
    "cost, ww, bb = grad_des_multi(X_train, yy_train, C, 0.8, epochs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "375b0f59-b39c-42c2-a576-e7e1f79f77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making predictions using the weights and bias found\n",
    "def predict_class(X, ww, bb):\n",
    "    return np.argmax(softmax(np.dot(X, ww)+ bb), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## Prediction for train, validation and test Data\n",
    "predc_train = predict_class(X_train, ww, bb)\n",
    "predc_val = predict_class(X_val, ww, bb)\n",
    "predc_test = predict_class(X_test, ww, bb)\n",
    "\n",
    "\n",
    "\n",
    "## Getting the accuracy of the model\n",
    "def accuracy(yy_pred, yy):\n",
    "    return 100*np.sum(yy_pred==yy)/len(yy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0fe056-c2f9-4062-987c-6e955acc76f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train Data is: 84.0%\n",
      "Accuracy on Validation Data is: 80.0%\n",
      "Accuracy on Test Data is: 80.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Train Data is: {0}%\".format(accuracy(predc_train, yy_train)))\n",
    "print(\"Accuracy on Validation Data is: {0}%\".format(accuracy(predc_val, yy_val)))\n",
    "print(\"Accuracy on Test Data is: {0}%\".format(accuracy(predc_test, yy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c4d3397-8b29-4d6d-9f25-a8c1c9a10086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data is: 93.0%\n",
      "Accuracy on Validation Data is: 90.0%\n",
      "Accuracy on Test Data is: 100.0%\n"
     ]
    }
   ],
   "source": [
    "## Softamx regression using inbuilt functions\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## Fitting the model to inbuilt functions\n",
    "softReg = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs')\n",
    "softReg.fit(X_train, yy_train)\n",
    "\n",
    "## Making predictions using softreg.predict\n",
    "y_pred_train = softReg.predict(X_train)\n",
    "y_pred_val = softReg.predict(X_val)\n",
    "y_pred_test = softReg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on Test Data is: {0}%\".format(100*np.sum(y_pred_train==yy_train)/len(yy_train)))\n",
    "print(\"Accuracy on Validation Data is: {0}%\".format(100*np.sum(y_pred_val==yy_val)/len(yy_val)))\n",
    "print(\"Accuracy on Test Data is: {0}%\".format(100*np.sum(y_pred_test==yy_test)/len(yy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9902c80-cbae-4781-85e9-5a00e8a63eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 0th epoch => 0.0%\n",
      "Accuracy for 1000th epoch => 98.0%\n",
      "Accuracy for 2000th epoch => 98.0%\n",
      "Accuracy for 3000th epoch => 98.0%\n",
      "Accuracy for 4000th epoch => 98.0%\n",
      "Accuracy for 5000th epoch => 98.0%\n",
      "Accuracy for 6000th epoch => 98.0%\n",
      "Accuracy for 7000th epoch => 98.0%\n",
      "Accuracy for 8000th epoch => 98.0%\n",
      "Accuracy for 9000th epoch => 98.0%\n"
     ]
    }
   ],
   "source": [
    "## Building a two layer Neural Network for better performance\n",
    "\n",
    "## Defining RELU to add non-linearity\n",
    "def relu(x):\n",
    "    x = np.int_(x)\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "## Defining the derivative of relu\n",
    "def D_relu(a):\n",
    "    return a>0\n",
    "\n",
    "## Defining function to get predictions\n",
    "def predict_classNN(A2):\n",
    "    return np.argmax(A2, axis=1)\n",
    "\n",
    "## defining the values for initial parameters\n",
    "def initial_params():\n",
    "    ww1 = np.random.randn(len(X_train[1]), 20)\n",
    "    bb1 = np.zeros((20))\n",
    "    \n",
    "    ww2 = np.random.randn(20, 3)\n",
    "    bb2 = np.zeros((3))\n",
    "    \n",
    "    return  ww1, bb1, ww2, bb2\n",
    "\n",
    "\n",
    "## Function to do Forward propagation\n",
    "def forward_prop(X, ww1, ww2, bb1, bb2, pred= False):\n",
    "    h1 = np.dot(X, ww1)+ bb1\n",
    "    A1 = relu(h1)\n",
    "    h2 = np.dot(h1, ww2)+ bb2\n",
    "    A2 = softmax(h2)\n",
    "    if pred:\n",
    "        return A2\n",
    "    return h1, h2, A1, A2\n",
    "\n",
    "## Function to do Backward propagation\n",
    "def backward_prop(X, yy, h1, h2, A1, A2, ww2):\n",
    "    N = len(yy)\n",
    "    yy = one_hot(yy, 3)\n",
    "    dA2 = A2 - yy\n",
    "    dww2 = 1/N * np.dot(np.transpose(h1), dA2)\n",
    "    dbb2 = 1/N * np.sum(dA2)\n",
    "    dA1 = np.dot(dA2, np.transpose(ww2)) * D_relu(A1)\n",
    "    dww1 = 1/N * np.dot(np.transpose(X), dA1)\n",
    "    dbb1 = 1/N * np.sum(dA1)\n",
    "    \n",
    "    return dww1, dww2, dbb1, dbb2\n",
    "\n",
    "## Updating the parameters after doing backward prop\n",
    "def update_param(ww1, ww2, bb1, bb2, dww1, dww2, dbb1, dbb2, step_size):\n",
    "    ww1 = ww1 - step_size* dww1\n",
    "    ww2 = ww2 - step_size* dww2\n",
    "    \n",
    "    bb1 = bb1 - step_size* dbb1\n",
    "    bb2 = bb2 - step_size* dbb2\n",
    "    \n",
    "    return ww1, ww2, bb1, bb2\n",
    "\n",
    "## Defining a gradient descent helper for Neural Network \n",
    "def gradient_desc_nn(X, yy, ww1, bb1, ww2, bb2, epochs, step_size, pred):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        h1, h2, A1, A2 = forward_prop(X, ww1, ww2, bb1, bb2)\n",
    "\n",
    "        dww1, dww2, dbb1, dbb2 = backward_prop(X, yy, h1, h2, A1, A2, ww2)\n",
    "        ww1, ww2, bb1, bb2 = update_param(ww1, ww2, bb1, bb2, dww1, dww2, dbb1, dbb2, step_size)\n",
    "        \n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(\"Accuracy for {0}th epoch => {1}%\".format(i, accuracy(predict_classNN(A2), yy)))\n",
    "    \n",
    "    return ww1, ww2, bb1, bb2    \n",
    "        \n",
    "ww1, bb1, ww2, bb2 = initial_params()   ## initializing the params\n",
    "\n",
    "## Extracting the params\n",
    "ww1, ww2, bb1, bb2 = gradient_desc_nn(X_train, yy_train, ww1, bb1, ww2, bb2, 10000, 0.1, True)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30333ac-4cfa-41fa-aeda-8b1d486657d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Data is: 100.0%\n",
      "Accuracy on Test Data is: 100.0%\n"
     ]
    }
   ],
   "source": [
    "## getting predictions for validation and test set for fitted NN\n",
    "pred_valnn = predict_classNN(forward_prop(X_val, ww1, ww2, bb1, bb2, True))\n",
    "pred_testnn = predict_classNN(forward_prop(X_test, ww1, ww2, bb1, bb2, True))\n",
    "\n",
    "\n",
    "print(\"Accuracy on Validation Data is: {0}%\".format(accuracy(pred_valnn, yy_val)))\n",
    "print(\"Accuracy on Test Data is: {0}%\".format(accuracy(pred_testnn, yy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c406be7-a0e7-4f35-bf50-88b6f2a90b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 2 1 1 2 0 2 0 0 1 0 2 2 2 1 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(pred_testnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb4af00e-edf5-405a-95b1-23e2b65f6a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 2., 1., 1., 2., 0., 2., 0., 0., 1., 0., 2., 2., 2., 1.,\n",
       "       0., 2., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857de8d9-6b65-41a9-b280-77b4a01575b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d86e9-d0bb-4b88-b299-4b742a57676f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e12e15-ba4e-46f4-9593-7b935e5d792c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395610a2-2ec1-4b1b-8990-ff24ffc88b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510e6b6-545f-4a63-836e-d826527d463c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c8389-150d-4c54-93fb-9ca6811c1455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c489aa-a4ee-49d1-84cd-0a0c57e9a6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9efeb-f712-4ca6-a552-5d6ee508e0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d6595-78ec-4ba7-bbe4-4e035776a459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
