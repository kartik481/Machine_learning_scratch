{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124e9f66-7a03-4279-a86c-3ade7859ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the required libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "iris = datasets.load_iris() ## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec04118-c8c0-4e0b-aac2-5f1bdfd0b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.concatenate((iris.data, iris.target[:,None]), axis=1)\n",
    "\n",
    "# Shuffling the data \n",
    "np.random.shuffle(Data)\n",
    "\n",
    "## Slicing the Dataset as required for labels \n",
    "X = Data[:,:4]\n",
    "yy = Data[:,4]\n",
    " \n",
    "## Scaling the data to make gradient descent work smoothly\n",
    "\n",
    "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec43a6e-6e13-46f7-9446-afdf314d58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data is already cleaned so no need of preprocessing\n",
    "X_train = X[:100,:]\n",
    "X_val = X[100:130,:]\n",
    "X_test = X[130:150,:]\n",
    "\n",
    "yy_train = yy[:100]\n",
    "yy_val = yy[100:130]\n",
    "yy_test = yy[130:150]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de351873-2301-4f83-8058-3bd65f48554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear regression Using the least square method \n",
    "\n",
    "def lin_reg(X, yy, alpha):\n",
    "    k = len(X[1])\n",
    "    yy = np.concatenate((yy, np.zeros(k))) \n",
    "    z_k = np.sqrt(alpha) * np.eye(k)\n",
    "    X = np.vstack((X,z_k))  \n",
    "    \n",
    "    b = np.concatenate((np.ones(len(X)-k), np.zeros(k)))[:,None]\n",
    "\n",
    "    X = np.insert(X,[0],b,axis=1)\n",
    "\n",
    "    w_fit=np.linalg.lstsq(X, yy, rcond=None)[0]\n",
    "    \n",
    "    \n",
    "    return w_fit[1:], w_fit[0] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c8a8d6-e16d-4ed1-ae38-be91a202bcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias is: -0.02385942299664876\n",
      "Weights are: \n",
      " [ 0.22334537 -0.26152559  0.92774672  1.30104487]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = 1 ## value for lambda parameter\n",
    "\n",
    "## Extracting the required parameters\n",
    "ww0, bb0 = lin_reg(X_train, yy_train, alpha)\n",
    "\n",
    "print(\"Bias is:\",bb0)\n",
    "print(\"Weights are:\",\"\\n\",ww0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d96c880-b7e2-4f95-946c-f9245b06dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cost functions\n",
    "\n",
    "## Mean Square error cost function\n",
    "def mse(pred,yy):\n",
    "    return np.mean((pred-yy)**2)\n",
    "\n",
    "## mLogloss for multi-classification\n",
    "def mlogloss(pred, yy):\n",
    "    yy = np.int_(yy)\n",
    "    return -np.mean(np.log(pred[np.arange(len(yy)), yy]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d099baaa-4c1c-4504-b031-b102d4bbcef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means square for training set(using least square method): 0.05145419928189548\n",
      "Means square for validation set(using least square method): 0.06793670471653827\n"
     ]
    }
   ],
   "source": [
    "## for least square method\n",
    "pred1_train = np.dot(X_train,ww0)+bb0\n",
    "pred2_val = np.dot(X_val,ww0)+bb0\n",
    "print(\"Means square for training set(using least square method):\",mse(pred1_train, yy_train))\n",
    "print(\"Means square for validation set(using least square method):\",mse(pred2_val, yy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1417ed8c-9db6-4d8b-98af-2b3fbaab9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the softmax function\n",
    "def softmax(x):\n",
    "    \n",
    "    # subtracting the max of z for numerical stability.\n",
    "    res = np.exp(x - np.max(x))\n",
    "    \n",
    "    # Calculating softmax for all examples.\n",
    "    for i in range(len(x)):\n",
    "        res[i] /= np.sum(res[i])\n",
    "        \n",
    "    return res\n",
    "\n",
    "## Defining one-hot encoder\n",
    "def one_hot(yy, c):\n",
    "    yy = np.int_(yy)\n",
    "    yy_hot = np.zeros((len(yy), c))\n",
    "    yy_hot[np.arange(len(yy)), yy] = 1\n",
    "\n",
    "    return yy_hot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Simple gradient descent method for linear regression\n",
    "\n",
    "def grad_des(X_train, yy_train, learning_rate, epochs):\n",
    "    n=len(X_train)\n",
    "    ww = np.random.randn(len(X[1]))\n",
    "    bb = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        yy_pred = np.dot(X_train, ww)+bb\n",
    "        \n",
    "        \n",
    "        cost = mse(yy_pred, yy_train)\n",
    "        if i%100==0:\n",
    "            print(\"MSE(train) for {0}th epoch is {1}\".format(i, cost))\n",
    "        D_ww = -2/n * np.sum(np.transpose(X_train) * (yy_train-yy_pred)) \n",
    "        D_bb = -2/n * np.sum((yy_train-yy_pred))\n",
    "        \n",
    "        ## Updating the parameters\n",
    "        ww -=learning_rate*D_ww\n",
    "        bb -=learning_rate*D_bb\n",
    "        \n",
    "        ## plotting the cost w.r.t to each iteration\n",
    "        plt.scatter(i, cost)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Cost\")\n",
    "        \n",
    "## Gradient descent for softmax algorithm\n",
    "def grad_des_multi(X_train, yy_train, C, learning_rate, epochs):\n",
    "    N, M = X_train.shape\n",
    "    ww = np.random.randn(M,C)\n",
    "    bb = np.random.randn(C)\n",
    "    cost =[]\n",
    "    for i in range(epochs):\n",
    "        yy_pred = softmax(np.dot(X_train, ww)+bb)\n",
    "        \n",
    "        yy_hot = one_hot(yy_train, C)\n",
    "        \n",
    "        ## Gradient of mlog-loss w.r.t ww and bb\n",
    "        D_ww = (1/N) * np.dot(np.transpose(X_train),(yy_pred - yy_hot))\n",
    "        D_bb = (1/N) * np.sum(yy_pred - yy_hot)\n",
    "        \n",
    "        ## Updating the parameters\n",
    "        \n",
    "        ww = ww - learning_rate * D_ww\n",
    "        bb = bb - learning_rate * D_bb\n",
    "        \n",
    "\n",
    "        loss = mlogloss(yy_pred, yy_train)\n",
    "        cost.append(loss)\n",
    "        if i%1000==0:\n",
    "            print(\"loss for {0}th epoch => {1}\".format(i, loss))\n",
    "        plt.scatter(i, loss)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Cost\")\n",
    "    return cost, ww, bb\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83daff05-fb08-47d6-9b15-96a042f5d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 0th epoch is 1.0947858881917854\n",
      "loss for 1000th epoch is 0.4000082801087101\n",
      "loss for 2000th epoch is 0.37914612073876214\n",
      "loss for 3000th epoch is 0.37135191810238916\n",
      "loss for 4000th epoch is 0.3677567586737679\n",
      "loss for 5000th epoch is 0.36586837265514577\n",
      "loss for 6000th epoch is 0.36476882790306675\n",
      "loss for 7000th epoch is 0.3640675299819318\n",
      "loss for 8000th epoch is 0.36358181475955315\n",
      "loss for 9000th epoch is 0.3632201909617629\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Total no of iteration to do\n",
    "epochs = 10000\n",
    "\n",
    "#grad_des(X_train, yy_train, 0.1, epochs)\n",
    "\n",
    "C = 3   ## No. of classes\n",
    "\n",
    "## Extracting the required parameters \n",
    "cost, ww, bb = grad_des_multi(X_train, yy_train, C, 0.9, epochs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "375b0f59-b39c-42c2-a576-e7e1f79f77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making predictions using the weights and bias found\n",
    "def predict_class(X, ww, bb):\n",
    "    return np.argmax(softmax(np.dot(X, ww)+ bb), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## Prediction for train, validation and test Data\n",
    "predc_train = predict_class(X_train, ww, bb)\n",
    "predc_val = predict_class(X_val, ww, bb)\n",
    "predc_test = predict_class(X_test, ww, bb)\n",
    "\n",
    "\n",
    "\n",
    "## Getting the accuracy of the model\n",
    "def accuracy(yy_pred, yy):\n",
    "    return 100*np.sum(yy_pred==yy)/len(yy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0fe056-c2f9-4062-987c-6e955acc76f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train Data is: 84.0%\n",
      "Accuracy on Validation Data is: 80.0%\n",
      "Accuracy on Test Data is: 80.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Train Data is: {0}%\".format(accuracy(predc_train, yy_train)))\n",
    "print(\"Accuracy on Validation Data is: {0}%\".format(accuracy(predc_val, yy_val)))\n",
    "print(\"Accuracy on Test Data is: {0}%\".format(accuracy(predc_test, yy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c4d3397-8b29-4d6d-9f25-a8c1c9a10086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data is: 93.0%\n",
      "Accuracy on Validation Data is: 90.0%\n",
      "Accuracy on Test Data is: 100.0%\n"
     ]
    }
   ],
   "source": [
    "## Softamx regression using inbuilt functions\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## Fitting the model to inbuilt functions\n",
    "softReg = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs')\n",
    "softReg.fit(X_train, yy_train)\n",
    "\n",
    "## Making predictions using softreg.predict\n",
    "y_pred_train = softReg.predict(X_train)\n",
    "y_pred_val = softReg.predict(X_val)\n",
    "y_pred_test = softReg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on Test Data is: {0}%\".format(100*np.sum(y_pred_train==yy_train)/len(yy_train)))\n",
    "print(\"Accuracy on Validation Data is: {0}%\".format(100*np.sum(y_pred_val==yy_val)/len(yy_val)))\n",
    "print(\"Accuracy on Test Data is: {0}%\".format(100*np.sum(y_pred_test==yy_test)/len(yy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9902c80-cbae-4781-85e9-5a00e8a63eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 0th epoch => 40.0\n",
      "Accuracy for 1000th epoch => 98.0\n",
      "Accuracy for 2000th epoch => 97.0\n",
      "Accuracy for 3000th epoch => 98.0\n",
      "Accuracy for 4000th epoch => 98.0\n",
      "Accuracy for 5000th epoch => 98.0\n",
      "Accuracy for 6000th epoch => 98.0\n",
      "Accuracy for 7000th epoch => 98.0\n",
      "Accuracy for 8000th epoch => 98.0\n",
      "Accuracy for 9000th epoch => 98.0\n"
     ]
    }
   ],
   "source": [
    "## Building a two layer Neural Network for better performance\n",
    "\n",
    "## Defining RELU to add non-linearity\n",
    "def relu(x):\n",
    "    x = np.int_(x)\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "## Defining the derivative of relu\n",
    "def D_relu(a):\n",
    "    return a>0\n",
    "\n",
    "## Defining function to get predictions\n",
    "def predict_classNN(A2):\n",
    "    return np.argmax(A2, axis=1)\n",
    "\n",
    "## defining the values for initial parameters\n",
    "def initial_params():\n",
    "    ww1 = np.random.randn(len(X_train[1]), 20)\n",
    "    bb1 = np.random.randn(20)\n",
    "    \n",
    "    ww2 = np.random.randn(20, 3)\n",
    "    bb2 = np.random.randn(3)\n",
    "    \n",
    "    return  ww1, bb1, ww2, bb2\n",
    "\n",
    "\n",
    "## Function to do Forward propagation\n",
    "def forward_prop(X, ww1, ww2, bb1, bb2, pred= False):\n",
    "    h1 = np.dot(X, ww1)+ bb1\n",
    "    A1 = relu(h1)\n",
    "    h2 = np.dot(h1, ww2)+ bb2\n",
    "    A2 = softmax(h2)\n",
    "    if pred:\n",
    "        return A2\n",
    "    return h1, h2, A1, A2\n",
    "\n",
    "## Function to do Backward propagation\n",
    "def backward_prop(X, yy, h1, h2, A1, A2, ww2):\n",
    "    N = len(yy)\n",
    "    yy = one_hot(yy, 3)\n",
    "    dA2 = A2 - yy\n",
    "    dww2 = 1/N * np.dot(np.transpose(h1), dA2)\n",
    "    dbb2 = 1/N * np.sum(dA2)\n",
    "    dA1 = np.dot(dA2, np.transpose(ww2)) * D_relu(A1)\n",
    "    dww1 = 1/N * np.dot(np.transpose(X), dA1)\n",
    "    dbb1 = 1/N * np.sum(dA1)\n",
    "    \n",
    "    return dww1, dww2, dbb1, dbb2\n",
    "\n",
    "## Updating the parameters after doing backward prop\n",
    "def update_param(ww1, ww2, bb1, bb2, dww1, dww2, dbb1, dbb2, step_size):\n",
    "    ww1 = ww1 - step_size* dww1\n",
    "    ww2 = ww2 - step_size* dww2\n",
    "    \n",
    "    bb1 = bb1 - step_size* dbb1\n",
    "    bb2 = bb2 - step_size* dbb2\n",
    "    \n",
    "    return ww1, ww2, bb1, bb2\n",
    "\n",
    "def gradient_desc_nn(X, yy, ww1, bb1, ww2, bb2, epochs, step_size, pred):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        h1, h2, A1, A2 = forward_prop(X, ww1, ww2, bb1, bb2)\n",
    "\n",
    "        dww1, dww2, dbb1, dbb2 = backward_prop(X, yy, h1, h2, A1, A2, ww2)\n",
    "        ww1, ww2, bb1, bb2 = update_param(ww1, ww2, bb1, bb2, dww1, dww2, dbb1, dbb2, step_size)\n",
    "        \n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(\"Accuracy for {0}th epoch => {1}\".format(i, accuracy(predict_classNN(A2), yy)))\n",
    "    \n",
    "    return ww1, ww2, bb1, bb2    \n",
    "        \n",
    "ww1, bb1, ww2, bb2 = initial_params() \n",
    "ww1, ww2, bb1, bb2 = gradient_desc_nn(X_train, yy_train, ww1, bb1, ww2, bb2, 10000, 0.1, True)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c30333ac-4cfa-41fa-aeda-8b1d486657d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Data is: 100.0%\n",
      "Accuracy on Test Data is: 100.0%\n"
     ]
    }
   ],
   "source": [
    "## getting predictions for validation and test set for fitted NN\n",
    "pred_valnn = predict_classNN(forward_prop(X_val, ww1, ww2, bb1, bb2, True))\n",
    "pred_testnn = predict_classNN(forward_prop(X_test, ww1, ww2, bb1, bb2, True))\n",
    "\n",
    "\n",
    "print(\"Accuracy on Validation Data is: {0}%\".format(accuracy(pred_valnn, yy_val)))\n",
    "print(\"Accuracy on Test Data is: {0}%\".format(accuracy(pred_testnn, yy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c406be7-a0e7-4f35-bf50-88b6f2a90b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4af00e-edf5-405a-95b1-23e2b65f6a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857de8d9-6b65-41a9-b280-77b4a01575b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d86e9-d0bb-4b88-b299-4b742a57676f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e12e15-ba4e-46f4-9593-7b935e5d792c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395610a2-2ec1-4b1b-8990-ff24ffc88b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510e6b6-545f-4a63-836e-d826527d463c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c8389-150d-4c54-93fb-9ca6811c1455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c489aa-a4ee-49d1-84cd-0a0c57e9a6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9efeb-f712-4ca6-a552-5d6ee508e0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d6595-78ec-4ba7-bbe4-4e035776a459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
